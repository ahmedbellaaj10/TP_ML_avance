{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedbellaaj10/TP_ML_avance/blob/main/Lab_DL__RNN_CLASS__keras__2021_10_05__imdb__student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBFqSEkKqpCN"
      },
      "source": [
        "# Lab Deep Learning/ Recurrent Neural Networks/ in keras\n",
        "\n",
        "## Using Many-to-One for movie rating predicton\n",
        "\n",
        "**Author: geoffroy.peeters@telecom-paris.fr**\n",
        "\n",
        "**Version**: 2021/10/05 (changed to tensorfow.keras)\n",
        "\n",
        "For any remark or suggestion, please feel free to contact me.\n",
        "\n",
        "## Objective:\n",
        "We will implement two different networks to perform automatic rating (0 or 1) of a movie given the text of its review.\n",
        "We will use the ```imdb``` (internet movie database) dataset.\n",
        "\n",
        "The reviews are already available in the form of indexes that point to a word dictionary: each word is already encoded as an index in the dictionary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmkCSNaXLqjh"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "AOqjzDwioJj9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import Dense, Activation, Embedding, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
        "\n",
        "colab = True\n",
        "student = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5Yp4OQVvUtr"
      },
      "source": [
        "## Parameters of the model\n",
        "\n",
        "-  We only consider the ```top_words``` first words in the word dictionary\n",
        "- We truncate/zero-pad each sequence a length ```max_review_length```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ca8XkEkGXCDH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "4C_Pv7rYvRkM"
      },
      "outputs": [],
      "source": [
        "top_words = 5000\n",
        "max_review_length = 100\n",
        "INDEX_FROM = 3\n",
        "embedding_vector_length = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsNcRimyLzgP"
      },
      "source": [
        "## Import IMDB data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "82dMfknplQYJ"
      },
      "outputs": [],
      "source": [
        "# --- Import the IMDB data and only consider the ``top_words``` most used words\n",
        "np.load.__defaults__=(None, True, True, 'ASCII')\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words, index_from=INDEX_FROM)\n",
        "np.load.__defaults__=(None, False, True, 'ASCII')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSc5LmksOLyr"
      },
      "source": [
        "## Data content\n",
        "\n",
        "- ```X_train``` and ```X_test``` are numpy arrays of lists.\n",
        "  - each item in a list is the index in the word dictionary. So that a list is the sequence of index of words.\n",
        "\n",
        "- ```y_train``` and ```y_test``` are a numpy arrays of the same dimension as ```X_train``` and ```X_test```\n",
        "  - they contains the values 0 (bad movie) or 1 (good movie)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "WouODCPrtiuu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "50ba9f13-a8e5-4d97-971e-ca9f94e8256c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(X_train): <class 'numpy.ndarray'>\n",
            "number of training sequences: X_train.shape: (25000,)\n",
            "type(X_train[0]): <class 'list'>\n",
            "length of the first training sequence: len(X_train[0]): 218\n",
            "length of the second training sequence: len(X_train[1]): 189\n",
            "list of data of the first training sequence: X_train[0]: [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
            "maximum length of a training sequence: 2494\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtHklEQVR4nO3de3BUZZ7/8U8IdEuE7hgg6WQIGESByE2ihl6VxSGTgNHRFatEGWAUoWCDtRCFmJUfIm5NWFgvjBfYKVfj1oKIW6IjGcAQDIwaUFJGbpISJmxwoRMGTBoQwiXP74/55fxsCEJCbk94v6pOVfo833P6OY+x8+E5lw4zxhgBAABYpENrdwAAAKChCDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOt0bO0ONJfa2lodPHhQXbt2VVhYWGt3BwAAXAZjjI4dO6a4uDh16HDxeZZ2G2AOHjyo+Pj41u4GAABohAMHDqhnz54XbW+3AaZr166S/jYAHo+nlXsDAAAuRzAYVHx8vPN3/GLabYCpO23k8XgIMAAAWOZSl39wES8AALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdTq2dgeuZtc/k3fBuv0L01uhJwAA2IUZGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGCdBgWYpUuXavDgwfJ4PPJ4PPL7/Vq7dq3TPnLkSIWFhYUs06ZNC9lHeXm50tPTFRERoejoaM2ePVtnz54NqSksLNSwYcPkdrvVt29f5ebmNv4IAQBAu9OxIcU9e/bUwoULdeONN8oYo3feeUf333+/vv76a918882SpClTpmjBggXONhEREc7P586dU3p6unw+n7744gsdOnRIEydOVKdOnfS73/1OklRWVqb09HRNmzZNy5cvV0FBgZ544gnFxsYqLS2tKY4ZAABYLswYY65kB1FRUVq8eLEmT56skSNHaujQoXrllVfqrV27dq3uvfdeHTx4UDExMZKkZcuWKSsrS4cPH5bL5VJWVpby8vK0c+dOZ7tx48apqqpK69atu+x+BYNBeb1eVVdXy+PxXMkhNpvrn8m7YN3+hemt0BMAANqGy/373ehrYM6dO6eVK1fqxIkT8vv9zvrly5ere/fuGjhwoLKzs/Xjjz86bUVFRRo0aJATXiQpLS1NwWBQu3btcmpSUlJC3istLU1FRUU/25+amhoFg8GQBQAAtE8NOoUkSTt27JDf79epU6fUpUsXrV69WomJiZKkRx99VL1791ZcXJy2b9+urKwslZaW6oMPPpAkBQKBkPAiyXkdCAR+tiYYDOrkyZPq3Llzvf3KycnR888/39DDAQAAFmpwgOnXr59KSkpUXV2t//7v/9akSZO0adMmJSYmaurUqU7doEGDFBsbq1GjRmnfvn264YYbmrTj58vOzlZmZqbzOhgMKj4+vlnfEwAAtI4Gn0JyuVzq27evkpKSlJOToyFDhmjJkiX11iYnJ0uS9u7dK0ny+XyqqKgIqal77fP5frbG4/FcdPZFktxut3N3VN0CAADapyt+Dkxtba1qamrqbSspKZEkxcbGSpL8fr927NihyspKpyY/P18ej8c5DeX3+1VQUBCyn/z8/JDrbAAAwNWtQaeQsrOzNWbMGPXq1UvHjh3TihUrVFhYqPXr12vfvn1asWKF7rnnHnXr1k3bt2/XrFmzNGLECA0ePFiSlJqaqsTERE2YMEGLFi1SIBDQ3LlzlZGRIbfbLUmaNm2aXnvtNc2ZM0ePP/64Nm7cqFWrVikv78I7dgAAwNWpQQGmsrJSEydO1KFDh+T1ejV48GCtX79ev/rVr3TgwAFt2LBBr7zyik6cOKH4+HiNHTtWc+fOdbYPDw/XmjVrNH36dPn9fl177bWaNGlSyHNjEhISlJeXp1mzZmnJkiXq2bOn3nzzTZ4BAwAAHFf8HJi2iufAAABgn2Z/DgwAAEBrIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKzT4G+jRvM6/+F2PNgOAIALMQMDAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrNCjALF26VIMHD5bH45HH45Hf79fatWud9lOnTikjI0PdunVTly5dNHbsWFVUVITso7y8XOnp6YqIiFB0dLRmz56ts2fPhtQUFhZq2LBhcrvd6tu3r3Jzcxt/hAAAoN1pUIDp2bOnFi5cqOLiYm3btk2//OUvdf/992vXrl2SpFmzZunjjz/W+++/r02bNungwYN68MEHne3PnTun9PR0nT59Wl988YXeeecd5ebmat68eU5NWVmZ0tPTdffdd6ukpEQzZ87UE088ofXr1zfRIQMAANuFGWPMlewgKipKixcv1kMPPaQePXpoxYoVeuihhyRJe/bs0YABA1RUVKThw4dr7dq1uvfee3Xw4EHFxMRIkpYtW6asrCwdPnxYLpdLWVlZysvL086dO533GDdunKqqqrRu3brL7lcwGJTX61V1dbU8Hs+VHGKzuf6ZvEvW7F+Y3gI9AQCgbbjcv9+Nvgbm3LlzWrlypU6cOCG/36/i4mKdOXNGKSkpTk3//v3Vq1cvFRUVSZKKioo0aNAgJ7xIUlpamoLBoDOLU1RUFLKPupq6fVxMTU2NgsFgyAIAANqnBgeYHTt2qEuXLnK73Zo2bZpWr16txMREBQIBuVwuRUZGhtTHxMQoEAhIkgKBQEh4qWuva/u5mmAwqJMnT160Xzk5OfJ6vc4SHx/f0EMDAACWaHCA6devn0pKSrR161ZNnz5dkyZN0u7du5ujbw2SnZ2t6upqZzlw4EBrdwkAADSTjg3dwOVyqW/fvpKkpKQkffXVV1qyZIkefvhhnT59WlVVVSGzMBUVFfL5fJIkn8+nL7/8MmR/dXcp/bTm/DuXKioq5PF41Llz54v2y+12y+12N/RwAACAha74OTC1tbWqqalRUlKSOnXqpIKCAqettLRU5eXl8vv9kiS/368dO3aosrLSqcnPz5fH41FiYqJT89N91NXU7QMAAKBBMzDZ2dkaM2aMevXqpWPHjmnFihUqLCzU+vXr5fV6NXnyZGVmZioqKkoej0dPPvmk/H6/hg8fLklKTU1VYmKiJkyYoEWLFikQCGju3LnKyMhwZk+mTZum1157TXPmzNHjjz+ujRs3atWqVcrLu/QdOwAA4OrQoABTWVmpiRMn6tChQ/J6vRo8eLDWr1+vX/3qV5Kkl19+WR06dNDYsWNVU1OjtLQ0vfHGG8724eHhWrNmjaZPny6/369rr71WkyZN0oIFC5yahIQE5eXladasWVqyZIl69uypN998U2lpaU10yAAAwHZX/ByYtornwAAAYJ9mfw4MAABAayHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6DQowOTk5uu2229S1a1dFR0frgQceUGlpaUjNyJEjFRYWFrJMmzYtpKa8vFzp6emKiIhQdHS0Zs+erbNnz4bUFBYWatiwYXK73erbt69yc3Mbd4QAAKDdaVCA2bRpkzIyMrRlyxbl5+frzJkzSk1N1YkTJ0LqpkyZokOHDjnLokWLnLZz584pPT1dp0+f1hdffKF33nlHubm5mjdvnlNTVlam9PR03X333SopKdHMmTP1xBNPaP369Vd4uAAAoD3o2JDidevWhbzOzc1VdHS0iouLNWLECGd9RESEfD5fvfv45JNPtHv3bm3YsEExMTEaOnSoXnjhBWVlZWn+/PlyuVxatmyZEhIS9OKLL0qSBgwYoM8++0wvv/yy0tLSGnqMAACgnbmia2Cqq6slSVFRUSHrly9fru7du2vgwIHKzs7Wjz/+6LQVFRVp0KBBiomJcdalpaUpGAxq165dTk1KSkrIPtPS0lRUVHTRvtTU1CgYDIYs7cH1z+RdsAAAcLVr0AzMT9XW1mrmzJm64447NHDgQGf9o48+qt69eysuLk7bt29XVlaWSktL9cEHH0iSAoFASHiR5LwOBAI/WxMMBnXy5El17tz5gv7k5OTo+eefb+zhAAAAizQ6wGRkZGjnzp367LPPQtZPnTrV+XnQoEGKjY3VqFGjtG/fPt1www2N7+klZGdnKzMz03kdDAYVHx/fbO8HAABaT6NOIc2YMUNr1qzRp59+qp49e/5sbXJysiRp7969kiSfz6eKioqQmrrXddfNXKzG4/HUO/siSW63Wx6PJ2QBAADtU4MCjDFGM2bM0OrVq7Vx40YlJCRccpuSkhJJUmxsrCTJ7/drx44dqqysdGry8/Pl8XiUmJjo1BQUFITsJz8/X36/vyHdBQAA7VSDAkxGRob+67/+SytWrFDXrl0VCAQUCAR08uRJSdK+ffv0wgsvqLi4WPv379cf//hHTZw4USNGjNDgwYMlSampqUpMTNSECRP0zTffaP369Zo7d64yMjLkdrslSdOmTdNf/vIXzZkzR3v27NEbb7yhVatWadasWU18+AAAwEYNCjBLly5VdXW1Ro4cqdjYWGd57733JEkul0sbNmxQamqq+vfvr6eeekpjx47Vxx9/7OwjPDxca9asUXh4uPx+v37zm99o4sSJWrBggVOTkJCgvLw85efna8iQIXrxxRf15ptvcgs1AACQJIUZY0xrd6I5BINBeb1eVVdXt9nrYRp7S/T+helN3BMAANqGy/37zXchAQAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGCdBgWYnJwc3Xbbberatauio6P1wAMPqLS0NKTm1KlTysjIULdu3dSlSxeNHTtWFRUVITXl5eVKT09XRESEoqOjNXv2bJ09ezakprCwUMOGDZPb7Vbfvn2Vm5vbuCMEAADtToMCzKZNm5SRkaEtW7YoPz9fZ86cUWpqqk6cOOHUzJo1Sx9//LHef/99bdq0SQcPHtSDDz7otJ87d07p6ek6ffq0vvjiC73zzjvKzc3VvHnznJqysjKlp6fr7rvvVklJiWbOnKknnnhC69evb4JDBgAAtgszxpjGbnz48GFFR0dr06ZNGjFihKqrq9WjRw+tWLFCDz30kCRpz549GjBggIqKijR8+HCtXbtW9957rw4ePKiYmBhJ0rJly5SVlaXDhw/L5XIpKytLeXl52rlzp/Ne48aNU1VVldatW3dZfQsGg/J6vaqurpbH42nsITar65/Ja9R2+xemN3FPAABoGy737/cVXQNTXV0tSYqKipIkFRcX68yZM0pJSXFq+vfvr169eqmoqEiSVFRUpEGDBjnhRZLS0tIUDAa1a9cup+an+6irqdsHAAC4unVs7Ia1tbWaOXOm7rjjDg0cOFCSFAgE5HK5FBkZGVIbExOjQCDg1Pw0vNS117X9XE0wGNTJkyfVuXPnC/pTU1Ojmpoa53UwGGzsoQEAgDau0TMwGRkZ2rlzp1auXNmU/Wm0nJwceb1eZ4mPj2/tLgEAgGbSqAAzY8YMrVmzRp9++ql69uzprPf5fDp9+rSqqqpC6isqKuTz+Zya8+9Kqnt9qRqPx1Pv7IskZWdnq7q62lkOHDjQmEMDAAAWaFCAMcZoxowZWr16tTZu3KiEhISQ9qSkJHXq1EkFBQXOutLSUpWXl8vv90uS/H6/duzYocrKSqcmPz9fHo9HiYmJTs1P91FXU7eP+rjdbnk8npAFAAC0Tw26BiYjI0MrVqzQRx99pK5duzrXrHi9XnXu3Fler1eTJ09WZmamoqKi5PF49OSTT8rv92v48OGSpNTUVCUmJmrChAlatGiRAoGA5s6dq4yMDLndbknStGnT9Nprr2nOnDl6/PHHtXHjRq1atUp5eY27awcAALQvDZqBWbp0qaqrqzVy5EjFxsY6y3vvvefUvPzyy7r33ns1duxYjRgxQj6fTx988IHTHh4erjVr1ig8PFx+v1+/+c1vNHHiRC1YsMCpSUhIUF5envLz8zVkyBC9+OKLevPNN5WWltYEhwwAAGx3Rc+Bact4DgwAAPZpkefAAAAAtAYCDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6zT6yxzRes6//ZrbqgEAVxtmYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArNPgALN582bdd999iouLU1hYmD788MOQ9t/+9rcKCwsLWUaPHh1Sc/ToUY0fP14ej0eRkZGaPHmyjh8/HlKzfft23XXXXbrmmmsUHx+vRYsWNfzoAABAu9TgAHPixAkNGTJEr7/++kVrRo8erUOHDjnLu+++G9I+fvx47dq1S/n5+VqzZo02b96sqVOnOu3BYFCpqanq3bu3iouLtXjxYs2fP19/+MMfGtpdAADQDnVs6AZjxozRmDFjfrbG7XbL5/PV2/btt99q3bp1+uqrr3TrrbdKkl599VXdc889+rd/+zfFxcVp+fLlOn36tN566y25XC7dfPPNKikp0UsvvRQSdAAAwNWpWa6BKSwsVHR0tPr166fp06fryJEjTltRUZEiIyOd8CJJKSkp6tChg7Zu3erUjBgxQi6Xy6lJS0tTaWmpfvjhh3rfs6amRsFgMGQBAADtU5MHmNGjR+s///M/VVBQoH/913/Vpk2bNGbMGJ07d06SFAgEFB0dHbJNx44dFRUVpUAg4NTExMSE1NS9rqs5X05Ojrxer7PEx8c39aEBAIA2osGnkC5l3Lhxzs+DBg3S4MGDdcMNN6iwsFCjRo1q6rdzZGdnKzMz03kdDAYJMQAAtFPNfht1nz591L17d+3du1eS5PP5VFlZGVJz9uxZHT161LluxufzqaKiIqSm7vXFrq1xu93yeDwhCwAAaJ+aPcB8//33OnLkiGJjYyVJfr9fVVVVKi4udmo2btyo2tpaJScnOzWbN2/WmTNnnJr8/Hz169dP1113XXN3GQAAtHENDjDHjx9XSUmJSkpKJEllZWUqKSlReXm5jh8/rtmzZ2vLli3av3+/CgoKdP/996tv375KS0uTJA0YMECjR4/WlClT9OWXX+rzzz/XjBkzNG7cOMXFxUmSHn30UblcLk2ePFm7du3Se++9pyVLloScIgIAAFevBgeYbdu26ZZbbtEtt9wiScrMzNQtt9yiefPmKTw8XNu3b9evf/1r3XTTTZo8ebKSkpL05z//WW6329nH8uXL1b9/f40aNUr33HOP7rzzzpBnvHi9Xn3yyScqKytTUlKSnnrqKc2bN49bqAEAgCQpzBhjWrsTzSEYDMrr9aq6urrNXg9z/TN5TbKf/QvTm2Q/AAC0tsv9+93kdyGh5dUXhAg1AID2jC9zBAAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDrdRt6Cmeu4LAABXO2ZgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6fJVAO3X+1xbsX5jeSj0BAKDpMQMDAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOz4FpJuc/hwUAADQdZmAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUaHGA2b96s++67T3FxcQoLC9OHH34Y0m6M0bx58xQbG6vOnTsrJSVF3333XUjN0aNHNX78eHk8HkVGRmry5Mk6fvx4SM327dt111136ZprrlF8fLwWLVrU8KMDAADtUoMDzIkTJzRkyBC9/vrr9bYvWrRIv//977Vs2TJt3bpV1157rdLS0nTq1CmnZvz48dq1a5fy8/O1Zs0abd68WVOnTnXag8GgUlNT1bt3bxUXF2vx4sWaP3++/vCHPzTiEAEAQHsTZowxjd44LEyrV6/WAw88IOlvsy9xcXF66qmn9PTTT0uSqqurFRMTo9zcXI0bN07ffvutEhMT9dVXX+nWW2+VJK1bt0733HOPvv/+e8XFxWnp0qV69tlnFQgE5HK5JEnPPPOMPvzwQ+3Zs+ey+hYMBuX1elVdXS2Px9PYQ2y0tvZdSPsXprd2FwAAuKTL/fvdpNfAlJWVKRAIKCUlxVnn9XqVnJysoqIiSVJRUZEiIyOd8CJJKSkp6tChg7Zu3erUjBgxwgkvkpSWlqbS0lL98MMP9b53TU2NgsFgyAIAANqnJg0wgUBAkhQTExOyPiYmxmkLBAKKjo4Oae/YsaOioqJCaurbx0/f43w5OTnyer3OEh8ff+UHBAAA2qR2cxdSdna2qqurneXAgQOt3SUAANBMmjTA+Hw+SVJFRUXI+oqKCqfN5/OpsrIypP3s2bM6evRoSE19+/jpe5zP7XbL4/GELAAAoH3q2JQ7S0hIkM/nU0FBgYYOHSrpbxfjbN26VdOnT5ck+f1+VVVVqbi4WElJSZKkjRs3qra2VsnJyU7Ns88+qzNnzqhTp06SpPz8fPXr10/XXXddU3b5qlHfRcVc2AsAsFWDZ2COHz+ukpISlZSUSPrbhbslJSUqLy9XWFiYZs6cqX/5l3/RH//4R+3YsUMTJ05UXFycc6fSgAEDNHr0aE2ZMkVffvmlPv/8c82YMUPjxo1TXFycJOnRRx+Vy+XS5MmTtWvXLr333ntasmSJMjMzm+zAAQCAvRo8A7Nt2zbdfffdzuu6UDFp0iTl5uZqzpw5OnHihKZOnaqqqirdeeedWrduna655hpnm+XLl2vGjBkaNWqUOnTooLFjx+r3v/+90+71evXJJ58oIyNDSUlJ6t69u+bNmxfyrBgAAHD1uqLnwLRlPAfm0jiFBABoa1rlOTAAAAAtgQADAACs06R3IV3NbDhlBABAe8EMDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADW4cscr2L1fQHl/oXprdATAAAahhkYAABgHQIMAACwDgEGAABYh2tgEOL862K4JgYA0BYxAwMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1uGrBPCzzv9qAYmvFwAAtD5mYAAAgHUIMAAAwDoEGAAAYB2ugUGDnX9dDNfEAABaGjMwAADAOk0eYObPn6+wsLCQpX///k77qVOnlJGRoW7duqlLly4aO3asKioqQvZRXl6u9PR0RUREKDo6WrNnz9bZs2ebuqsAAMBSzXIK6eabb9aGDRv+/5t0/P9vM2vWLOXl5en999+X1+vVjBkz9OCDD+rzzz+XJJ07d07p6eny+Xz64osvdOjQIU2cOFGdOnXS7373u+boLgAAsEyzBJiOHTvK5/NdsL66ulr/8R//oRUrVuiXv/ylJOntt9/WgAEDtGXLFg0fPlyffPKJdu/erQ0bNigmJkZDhw7VCy+8oKysLM2fP18ul6s5ugwAACzSLNfAfPfdd4qLi1OfPn00fvx4lZeXS5KKi4t15swZpaSkOLX9+/dXr169VFRUJEkqKirSoEGDFBMT49SkpaUpGAxq165dF33PmpoaBYPBkAUAALRPTR5gkpOTlZubq3Xr1mnp0qUqKyvTXXfdpWPHjikQCMjlcikyMjJkm5iYGAUCAUlSIBAICS917XVtF5OTkyOv1+ss8fHxTXtgAACgzWjyU0hjxoxxfh48eLCSk5PVu3dvrVq1Sp07d27qt3NkZ2crMzPTeR0MBgkxAAC0U81+G3VkZKRuuukm7d27Vz6fT6dPn1ZVVVVITUVFhXPNjM/nu+CupLrX9V1XU8ftdsvj8YQsAACgfWr2AHP8+HHt27dPsbGxSkpKUqdOnVRQUOC0l5aWqry8XH6/X5Lk9/u1Y8cOVVZWOjX5+fnyeDxKTExs7u4CAAALNPkppKefflr33XefevfurYMHD+q5555TeHi4HnnkEXm9Xk2ePFmZmZmKioqSx+PRk08+Kb/fr+HDh0uSUlNTlZiYqAkTJmjRokUKBAKaO3euMjIy5Ha7m7q7AADAQk0eYL7//ns98sgjOnLkiHr06KE777xTW7ZsUY8ePSRJL7/8sjp06KCxY8eqpqZGaWlpeuONN5ztw8PDtWbNGk2fPl1+v1/XXnutJk2apAULFjR1VwEAgKXCjDGmtTvRHILBoLxer6qrq1vkepjzvx/oasJ3IQEAmsrl/v3mu5AAAIB1+DZqXLH6Zp+YlQEANCdmYAAAgHWYgUGzOH9WhhkZAEBTYgYGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1uAsJLYJnxQAAmhIzMAAAwDoEGAAAYB1OIaHV8LA7AEBjMQMDAACswwwM2gwu9AUAXC5mYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4X8aJN41ZrAEB9mIEBAADWYQYGVuFWawCAxAwMAACwEAEGAABYh1NIaHc4zQQA7R8BBtarL7AAANo3TiEBAADrMAODqwLPkwGA9oUZGAAAYB1mYHBV4kJfALAbAQb4fzjNBAD2IMAAF8EsDQC0XQSYRuC23asXszQA0DYQYIArcDmzNMzkAEDTI8AATexyZuja2kxOW+sPAFwKAQZoA1pyloZToADagzYdYF5//XUtXrxYgUBAQ4YM0auvvqrbb7+9tbsFtIjLmRVpTA0AtAdtNsC89957yszM1LJly5ScnKxXXnlFaWlpKi0tVXR0dGt3D2hxjTk1BQDtVZt9Eu9LL72kKVOm6LHHHlNiYqKWLVumiIgIvfXWW63dNQAA0Mra5AzM6dOnVVxcrOzsbGddhw4dlJKSoqKionq3qampUU1NjfO6urpakhQMBpu8f7U1Pzb5PoG2pNes9y9Yt/P5tFboCYCrTd3fbWPMz9a1yQDz17/+VefOnVNMTEzI+piYGO3Zs6febXJycvT8889fsD4+Pr5Z+ghcbbyvtHYPAFxNjh07Jq/Xe9H2NhlgGiM7O1uZmZnO69raWh09elTdunVTWFjYFe8/GAwqPj5eBw4ckMfjueL94eIY65bDWLccxrrlMNYto7nG2RijY8eOKS4u7mfr2mSA6d69u8LDw1VRURGyvqKiQj6fr95t3G633G53yLrIyMgm75vH4+F/iBbCWLccxrrlMNYth7FuGc0xzj8381KnTV7E63K5lJSUpIKCAmddbW2tCgoK5Pf7W7FnAACgLWiTMzCSlJmZqUmTJunWW2/V7bffrldeeUUnTpzQY4891tpdAwAArazNBpiHH35Yhw8f1rx58xQIBDR06FCtW7fuggt7W4rb7dZzzz13wWkqND3GuuUw1i2HsW45jHXLaO1xDjOXuk8JAACgjWmT18AAAAD8HAIMAACwDgEGAABYhwADAACsQ4C5TK+//rquv/56XXPNNUpOTtaXX37Z2l2yyvz58xUWFhay9O/f32k/deqUMjIy1K1bN3Xp0kVjx4694EGG5eXlSk9PV0REhKKjozV79mydPXu2pQ+lzdm8ebPuu+8+xcXFKSwsTB9++GFIuzFG8+bNU2xsrDp37qyUlBR99913ITVHjx7V+PHj5fF4FBkZqcmTJ+v48eMhNdu3b9ddd92la665RvHx8Vq0aFFzH1qbc6mx/u1vf3vB7/no0aNDahjrS8vJydFtt92mrl27Kjo6Wg888IBKS0tDaprqM6OwsFDDhg2T2+1W3759lZub29yH16ZczliPHDnygt/radOmhdS0ylgbXNLKlSuNy+Uyb731ltm1a5eZMmWKiYyMNBUVFa3dNWs899xz5uabbzaHDh1ylsOHDzvt06ZNM/Hx8aagoMBs27bNDB8+3Pzd3/2d03727FkzcOBAk5KSYr7++mvzpz/9yXTv3t1kZ2e3xuG0KX/605/Ms88+az744AMjyaxevTqkfeHChcbr9ZoPP/zQfPPNN+bXv/61SUhIMCdPnnRqRo8ebYYMGWK2bNli/vznP5u+ffuaRx55xGmvrq42MTExZvz48Wbnzp3m3XffNZ07dzb//u//3lKH2SZcaqwnTZpkRo8eHfJ7fvTo0ZAaxvrS0tLSzNtvv2127txpSkpKzD333GN69epljh8/7tQ0xWfGX/7yFxMREWEyMzPN7t27zauvvmrCw8PNunXrWvR4W9PljPXf//3fmylTpoT8XldXVzvtrTXWBJjLcPvtt5uMjAzn9blz50xcXJzJyclpxV7Z5bnnnjNDhgypt62qqsp06tTJvP/++866b7/91kgyRUVFxpi//eHo0KGDCQQCTs3SpUuNx+MxNTU1zdp3m5z/R7W2ttb4fD6zePFiZ11VVZVxu93m3XffNcYYs3v3biPJfPXVV07N2rVrTVhYmPnf//1fY4wxb7zxhrnuuutCxjorK8v069evmY+o7bpYgLn//vsvug1j3TiVlZVGktm0aZMxpuk+M+bMmWNuvvnmkPd6+OGHTVpaWnMfUpt1/lgb87cA80//9E8X3aa1xppTSJdw+vRpFRcXKyUlxVnXoUMHpaSkqKioqBV7Zp/vvvtOcXFx6tOnj8aPH6/y8nJJUnFxsc6cORMyxv3791evXr2cMS4qKtKgQYNCHmSYlpamYDCoXbt2teyBWKSsrEyBQCBkbL1er5KTk0PGNjIyUrfeeqtTk5KSog4dOmjr1q1OzYgRI+RyuZyatLQ0lZaW6ocffmiho7FDYWGhoqOj1a9fP02fPl1Hjhxx2hjrxqmurpYkRUVFSWq6z4yioqKQfdTVXM2f7eePdZ3ly5ere/fuGjhwoLKzs/Xjjz86ba011m32SbxtxV//+ledO3fugicAx8TEaM+ePa3UK/skJycrNzdX/fr106FDh/T888/rrrvu0s6dOxUIBORyuS748s2YmBgFAgFJUiAQqPe/QV0b6lc3NvWN3U/HNjo6OqS9Y8eOioqKCqlJSEi4YB91bdddd12z9N82o0eP1oMPPqiEhATt27dP//zP/6wxY8aoqKhI4eHhjHUj1NbWaubMmbrjjjs0cOBASWqyz4yL1QSDQZ08eVKdO3dujkNqs+oba0l69NFH1bt3b8XFxWn79u3KyspSaWmpPvjgA0mtN9YEGLSIMWPGOD8PHjxYycnJ6t27t1atWnXVfUig/Ro3bpzz86BBgzR48GDdcMMNKiws1KhRo1qxZ/bKyMjQzp079dlnn7V2V9q9i4311KlTnZ8HDRqk2NhYjRo1Svv27dMNN9zQ0t10cArpErp3767w8PALrm6vqKiQz+drpV7ZLzIyUjfddJP27t0rn8+n06dPq6qqKqTmp2Ps8/nq/W9Q14b61Y3Nz/3++nw+VVZWhrSfPXtWR48eZfyvUJ8+fdS9e3ft3btXEmPdUDNmzNCaNWv06aefqmfPns76pvrMuFiNx+O56v5hdbGxrk9ycrIkhfxet8ZYE2AuweVyKSkpSQUFBc662tpaFRQUyO/3t2LP7Hb8+HHt27dPsbGxSkpKUqdOnULGuLS0VOXl5c4Y+/1+7dixI+TDPz8/Xx6PR4mJiS3ef1skJCTI5/OFjG0wGNTWrVtDxraqqkrFxcVOzcaNG1VbW+t8UPn9fm3evFlnzpxxavLz89WvX7+r7pRGQ3z//fc6cuSIYmNjJTHWl8sYoxkzZmj16tXauHHjBafUmuozw+/3h+yjruZq+my/1FjXp6SkRJJCfq9bZawbffnvVWTlypXG7Xab3Nxcs3v3bjN16lQTGRkZcsU1ft5TTz1lCgsLTVlZmfn8889NSkqK6d69u6msrDTG/O2WyF69epmNGzeabdu2Gb/fb/x+v7N93W16qamppqSkxKxbt8706NGD26iNMceOHTNff/21+frrr40k89JLL5mvv/7a/M///I8x5m+3UUdGRpqPPvrIbN++3dx///313kZ9yy23mK1bt5rPPvvM3HjjjSG39lZVVZmYmBgzYcIEs3PnTrNy5UoTERFxVd3aa8zPj/WxY8fM008/bYqKikxZWZnZsGGDGTZsmLnxxhvNqVOnnH0w1pc2ffp04/V6TWFhYcituz/++KNT0xSfGXW39s6ePdt8++235vXXX7/qbqO+1Fjv3bvXLFiwwGzbts2UlZWZjz76yPTp08eMGDHC2UdrjTUB5jK9+uqrplevXsblcpnbb7/dbNmypbW7ZJWHH37YxMbGGpfLZX7xi1+Yhx9+2Ozdu9dpP3nypPnHf/xHc91115mIiAjzD//wD+bQoUMh+9i/f78ZM2aM6dy5s+nevbt56qmnzJkzZ1r6UNqcTz/91Ei6YJk0aZIx5m+3Uv+f//N/TExMjHG73WbUqFGmtLQ0ZB9HjhwxjzzyiOnSpYvxeDzmscceM8eOHQup+eabb8ydd95p3G63+cUvfmEWLlzYUofYZvzcWP/4448mNTXV9OjRw3Tq1Mn07t3bTJky5YJ/6DDWl1bfGEsyb7/9tlPTVJ8Zn376qRk6dKhxuVymT58+Ie9xNbjUWJeXl5sRI0aYqKgo43a7Td++fc3s2bNDngNjTOuMddj/OwAAAABrcA0MAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANb5v9sLDT+OFDwfAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"type(X_train):\", type(X_train))\n",
        "print(\"number of training sequences: X_train.shape:\", X_train.shape)\n",
        "print(\"type(X_train[0]):\",type(X_train[0]))\n",
        "print(\"length of the first training sequence: len(X_train[0]):\",len(X_train[0]))\n",
        "print(\"length of the second training sequence: len(X_train[1]):\",len(X_train[1]))\n",
        "print(\"list of data of the first training sequence: X_train[0]:\", X_train[0] )\n",
        "len_list = [len(train) for train in X_train]\n",
        "print(\"maximum length of a training sequence:\", max(len_list))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(len_list, 100);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I-cEKUh_HM4"
      },
      "source": [
        "## Details of how the reviews are encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "XcOwiMUT_HM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18fba61-9193-47e5-9cbf-a40e4d64e09b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> although i had seen <UNK> in a theater way back in <UNK> i couldn't remember anything of the plot except for vague images of kurt thomas running and fighting against a backdrop of stone walls and disappointment regarding the ending br br after reading some of the other reviews i picked up a copy of the newly released dvd to once again enter the world of <UNK> br br it turns out this is one of those films produced during the <UNK> that would go directly to video today the film stars <UNK> <UNK> kurt thomas as jonathan <UNK> <UNK> out of the blue to <UNK> the nation of <UNK> to enter and hopefully win the game a <UNK> <UNK> <UNK> by the khan who <UNK> his people by yelling what sounds like <UNK> power the goal of the mission involves the star wars defense system jonathan is trained in the martial arts by princess <UNK> who never speaks or leaves the house once trained tries to blend in with the <UNK> by wearing a bright red <UNK> with <UNK> of blue and white needless to say <UNK> finds himself running and fighting for his life along the stone streets of <UNK> on his way to a date with destiny and the game br br star kurt thomas was ill served by director robert <UNK> who it looks like was never on the set the so called script is just this side of incompetent see other reviews for the many <UNK> throughout the town of <UNK> has a few good moments but is ultimately ruined by bad editing the ending <UNK> still there's the <UNK> of a good action adventure here a hong kong version with more <UNK> action and faster pace might even be pretty good\n"
          ]
        }
      ],
      "source": [
        "word_to_id = imdb.get_word_index()\n",
        "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START>\"] = 1\n",
        "word_to_id[\"<UNK>\"] = 2\n",
        "\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}\n",
        "print(' '.join(id_to_word[id] for id in X_train[1000] ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Hfl42LGCugWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa1d9ba-a111-430c-d488-156f19ecf120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(y_train): <class 'numpy.ndarray'>\n",
            "y_train.shape: (25000,)\n"
          ]
        }
      ],
      "source": [
        "print(\"type(y_train):\", type(y_train))\n",
        "print(\"y_train.shape:\", y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "iVw65PNNuobX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6007b56-f0b9-4dda-9774-01c915e371db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test.shape: (25000,)\n",
            "y_test.shape: (25000,)\n"
          ]
        }
      ],
      "source": [
        "print(\"X_test.shape:\", X_test.shape)\n",
        "print(\"y_test.shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V18OA7oQNH3c"
      },
      "source": [
        "## Data processing\n",
        "\n",
        "Sequences (represented as a list of values) in ```X_train``` represent the reviews.\n",
        "They can have different length.\n",
        "To train the network we should modify them so that they all have the same length.\n",
        "We do this by:\n",
        "- truncating the ones that are too long\n",
        "- padding-with-zero them the ones that are too short.\n",
        "\n",
        "This is obtained using ```sequence.pad_sequences``` of keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "JhmiHsOGoRwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3f9f2b-5a74-4113-a940-47e4ffecb46b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(X_train[0]): 100\n",
            "len(X_train[1]): 100\n",
            "X_train[0]: [ 163   11 3215    2    4 1153    9  194  775    7    2    2  349 2637\n",
            "  148  605    2    2   15  123  125   68    2    2   15  349  165 4362\n",
            "   98    5    4  228    9   43    2 1157   15  299  120    5  120  174\n",
            "   11  220  175  136   50    9 4373  228    2    5    2  656  245 2350\n",
            "    5    4    2  131  152  491   18    2   32    2 1212   14    9    6\n",
            "  371   78   22  625   64 1382    9    8  168  145   23    4 1690   15\n",
            "   16    4 1355    5   28    6   52  154  462   33   89   78  285   16\n",
            "  145   95]\n"
          ]
        }
      ],
      "source": [
        "# --- truncate and pad input sequences\n",
        "import keras\n",
        "\n",
        "if student:\n",
        "    X_train = keras.utils.pad_sequences(\n",
        "    X_train,\n",
        "    maxlen=max_review_length,\n",
        "    dtype='int32',\n",
        "    padding='pre',\n",
        "    truncating='pre',\n",
        "    value=0\n",
        "    )\n",
        "    X_test = keras.utils.pad_sequences(\n",
        "    X_test,\n",
        "    maxlen=max_review_length,\n",
        "    dtype='int32',\n",
        "    padding='pre',\n",
        "    truncating='pre',\n",
        "    value=0\n",
        "    )\n",
        "    # --- START CODE HERE (01)\n",
        "    ...\n",
        "    # --- END CODE HERE\n",
        "\n",
        "print(\"len(X_train[0]):\", len(X_train[0]))\n",
        "print(\"len(X_train[1]):\", len(X_train[1]))\n",
        "print(\"X_train[0]:\", X_train[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "XZrWuxfyoB7w",
        "outputId": "c15a331e-6e6a-4d7f-ee13-a1e9e302ca69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlrDTuk5K65Q"
      },
      "source": [
        "# First model\n",
        "\n",
        "<img src=\"https://perso.telecom-paristech.fr/gpeeters/doc/Lab_DL_RNN_01.png\">\n",
        "\n",
        "In the first model, we will simply\n",
        "- learn a word embedding  (```Embedding``` layer in keras) and apply it to each item of the sequence,\n",
        "  -  in keras, embedding is not a matrix going from one-hot-encoding to embedding, but is a layer that goes from index-in-word-dictionary to embedding\n",
        "  - the embedding goes from ```top_words``` dimensions to  ```embedding_vector_length``` dimensions\n",
        "- average the embedding obtained for each word of a sequence over all words of the sequence (you should use ```K.mean``` and ```Lambda``` from the keras backend)\n",
        "- apply a fully connected (```Dense``` layer in keras) which output activation is a sigmoid (predicting the 0 or 1 rating)\n",
        "\n",
        "We will code this model\n",
        "- First, using the Sequential API of keras (https://keras.io/models/sequential/)\n",
        "- Secondly, using the Functional API of keras (https://keras.io/getting-started/functional-api-guide/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ufW00TGcs3Jj"
      },
      "outputs": [],
      "source": [
        "K.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train[4])"
      ],
      "metadata": {
        "id": "ENOqzYyzqc9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c884586e-0ec8-41bd-acc9-a3e7091f7304"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_words = 5000\n",
        "max_review_length = 100\n",
        "INDEX_FROM = 3\n",
        "embedding_vector_length = 32"
      ],
      "metadata": {
        "id": "-k_fNmK0sHl0"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "zspaUptgtW9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d1b2b8-fb2a-467d-ae01-d29ecd8b0e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 32)           160000    \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160033 (625.13 KB)\n",
            "Trainable params: 160033 (625.13 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# --- create the model\n",
        "# CODE-RNN1-2\n",
        "if student:\n",
        "    # --- START CODE HERE (02)\n",
        "    # --- Using the Sequential API\n",
        "    model = Sequential()\n",
        "    # model.add(Input(shape=(max_review_length,)))\n",
        "    model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\n",
        "    model.add(Lambda(lambda x: K.mean(x, axis=1)))\n",
        "    # model.add(Lambda(lambda x: K.mean(x)))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    ...\n",
        "    # --- END CODE HERE\n",
        "\n",
        "    # --- START CODE HERE (03)\n",
        "    # --- Using the Functional API\n",
        "    ...\n",
        "    # --- END CODE HERE\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = np.array(X_train)\n",
        "# X_test = np.array(X_test)\n",
        "# y_train = np.array(y_train)\n",
        "# y_test = np.array(y_test)\n",
        "\n",
        "X_train[0]"
      ],
      "metadata": {
        "id": "1ejHn6BTzKps",
        "outputId": "6d2bb83e-93e6-4272-ee20-d2eb45171bd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1415,   33,    6,   22,   12,  215,   28,   77,   52,    5,   14,\n",
              "        407,   16,   82,    2,    8,    4,  107,  117,    2,   15,  256,\n",
              "          4,    2,    7, 3766,    5,  723,   36,   71,   43,  530,  476,\n",
              "         26,  400,  317,   46,    7,    4,    2, 1029,   13,  104,   88,\n",
              "          4,  381,   15,  297,   98,   32, 2071,   56,   26,  141,    6,\n",
              "        194,    2,   18,    4,  226,   22,   21,  134,  476,   26,  480,\n",
              "          5,  144,   30,    2,   18,   51,   36,   28,  224,   92,   25,\n",
              "        104,    4,  226,   65,   16,   38, 1334,   88,   12,   16,  283,\n",
              "          5,   16, 4472,  113,  103,   32,   15,   16,    2,   19,  178,\n",
              "         32], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "X_train_tf = tf.convert_to_tensor(X_train, dtype=tf.int8)\n",
        "X_test_tf = tf.convert_to_tensor(X_test, dtype=tf.int8)"
      ],
      "metadata": {
        "id": "kPWqT4mi7gD5"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "pFXz4AS6tawQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344092bb-a3af-49c7-fd9f-6f49fff4e345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 4s 7ms/step - loss: 0.6694 - accuracy: 0.6385 - val_loss: 0.6383 - val_accuracy: 0.6602\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.6109 - accuracy: 0.6810 - val_loss: 0.5930 - val_accuracy: 0.6875\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.5828 - accuracy: 0.6951 - val_loss: 0.5782 - val_accuracy: 0.6935\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c3b98f1a620>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# --- compile and fit the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train_tf, y_train, epochs=3, batch_size=64, validation_data=(X_test_tf, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBqyzLJRUIsC"
      },
      "source": [
        "## Results\n",
        "\n",
        "After only 3 epochs, you should obtain an accuracy around 83-84% for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "nCALyP-Q_HNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18929d7-ee2b-439c-edac-916473ab37d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 68.04%\n"
          ]
        }
      ],
      "source": [
        "# --- Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRP-h4Xr_HNJ"
      },
      "source": [
        "## Using the trained embedding to find equivalence between words\n",
        "\n",
        "Since the embedding is part of the models, we can look at the trained embedding matrix $E$ and use it to get the most similar words (according to the trained matrix $E$) in the dictionary.\n",
        "Use the weights of the ```Embedding``` layer to find the most similar words to ```great```. We will use an Euclidean distance for that.\n",
        "- Retrieve the weights of the ```Embedding layer```\n",
        "- Get the position of ```great``` in the dictionary\n",
        "- Get the word-embedding of ```great```\n",
        "- Find (using Euclidean distance), the closest embedded-words to ```great```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[0].get_weights()# [0].shape"
      ],
      "metadata": {
        "id": "80kbJi1duJay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d462903-b3af-4b19-e6a3-9c617929e0e0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.05039876,  0.03491502, -0.00456951, ...,  0.05381323,\n",
              "         -0.02697828, -0.03344515],\n",
              "        [-0.26746938,  0.27718496, -0.35438618, ...,  0.29282212,\n",
              "          0.35783687, -0.31881604],\n",
              "        [ 0.0354566 ,  0.01855964,  0.03953954, ..., -0.06073724,\n",
              "         -0.05756662,  0.0500406 ],\n",
              "        ...,\n",
              "        [ 0.00788124, -0.01378564, -0.0267291 , ...,  0.00871025,\n",
              "         -0.0331553 ,  0.03128997],\n",
              "        [ 0.04944715, -0.01748539, -0.02958041, ..., -0.02042381,\n",
              "          0.03812034,  0.03184513],\n",
              "        [-0.0262017 , -0.02479223, -0.03007511, ..., -0.04437374,\n",
              "         -0.03960575,  0.0469785 ]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9BvXWch59hof",
        "outputId": "0b7387aa-61d7-43b6-e8dc-2d09f57664d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fawn': 34704,\n",
              " 'tsukino': 52009,\n",
              " 'nunnery': 52010,\n",
              " 'sonja': 16819,\n",
              " 'vani': 63954,\n",
              " 'woods': 1411,\n",
              " 'spiders': 16118,\n",
              " 'hanging': 2348,\n",
              " 'woody': 2292,\n",
              " 'trawling': 52011,\n",
              " \"hold's\": 52012,\n",
              " 'comically': 11310,\n",
              " 'localized': 40833,\n",
              " 'disobeying': 30571,\n",
              " \"'royale\": 52013,\n",
              " \"harpo's\": 40834,\n",
              " 'canet': 52014,\n",
              " 'aileen': 19316,\n",
              " 'acurately': 52015,\n",
              " \"diplomat's\": 52016,\n",
              " 'rickman': 25245,\n",
              " 'arranged': 6749,\n",
              " 'rumbustious': 52017,\n",
              " 'familiarness': 52018,\n",
              " \"spider'\": 52019,\n",
              " 'hahahah': 68807,\n",
              " \"wood'\": 52020,\n",
              " 'transvestism': 40836,\n",
              " \"hangin'\": 34705,\n",
              " 'bringing': 2341,\n",
              " 'seamier': 40837,\n",
              " 'wooded': 34706,\n",
              " 'bravora': 52021,\n",
              " 'grueling': 16820,\n",
              " 'wooden': 1639,\n",
              " 'wednesday': 16821,\n",
              " \"'prix\": 52022,\n",
              " 'altagracia': 34707,\n",
              " 'circuitry': 52023,\n",
              " 'crotch': 11588,\n",
              " 'busybody': 57769,\n",
              " \"tart'n'tangy\": 52024,\n",
              " 'burgade': 14132,\n",
              " 'thrace': 52026,\n",
              " \"tom's\": 11041,\n",
              " 'snuggles': 52028,\n",
              " 'francesco': 29117,\n",
              " 'complainers': 52030,\n",
              " 'templarios': 52128,\n",
              " '272': 40838,\n",
              " '273': 52031,\n",
              " 'zaniacs': 52133,\n",
              " '275': 34709,\n",
              " 'consenting': 27634,\n",
              " 'snuggled': 40839,\n",
              " 'inanimate': 15495,\n",
              " 'uality': 52033,\n",
              " 'bronte': 11929,\n",
              " 'errors': 4013,\n",
              " 'dialogs': 3233,\n",
              " \"yomada's\": 52034,\n",
              " \"madman's\": 34710,\n",
              " 'dialoge': 30588,\n",
              " 'usenet': 52036,\n",
              " 'videodrome': 40840,\n",
              " \"kid'\": 26341,\n",
              " 'pawed': 52037,\n",
              " \"'girlfriend'\": 30572,\n",
              " \"'pleasure\": 52038,\n",
              " \"'reloaded'\": 52039,\n",
              " \"kazakos'\": 40842,\n",
              " 'rocque': 52040,\n",
              " 'mailings': 52041,\n",
              " 'brainwashed': 11930,\n",
              " 'mcanally': 16822,\n",
              " \"tom''\": 52042,\n",
              " 'kurupt': 25246,\n",
              " 'affiliated': 21908,\n",
              " 'babaganoosh': 52043,\n",
              " \"noe's\": 40843,\n",
              " 'quart': 40844,\n",
              " 'kids': 362,\n",
              " 'uplifting': 5037,\n",
              " 'controversy': 7096,\n",
              " 'kida': 21909,\n",
              " 'kidd': 23382,\n",
              " \"error'\": 52044,\n",
              " 'neurologist': 52045,\n",
              " 'spotty': 18513,\n",
              " 'cobblers': 30573,\n",
              " 'projection': 9881,\n",
              " 'fastforwarding': 40845,\n",
              " 'sters': 52046,\n",
              " \"eggar's\": 52047,\n",
              " 'etherything': 52048,\n",
              " 'gateshead': 40846,\n",
              " 'airball': 34711,\n",
              " 'unsinkable': 25247,\n",
              " 'stern': 7183,\n",
              " \"cervi's\": 52049,\n",
              " 'dnd': 40847,\n",
              " 'dna': 11589,\n",
              " 'insecurity': 20601,\n",
              " \"'reboot'\": 52050,\n",
              " 'trelkovsky': 11040,\n",
              " 'jaekel': 52051,\n",
              " 'sidebars': 52052,\n",
              " \"sforza's\": 52053,\n",
              " 'distortions': 17636,\n",
              " 'mutinies': 52054,\n",
              " 'sermons': 30605,\n",
              " '7ft': 40849,\n",
              " 'boobage': 52055,\n",
              " \"o'bannon's\": 52056,\n",
              " 'populations': 23383,\n",
              " 'chulak': 52057,\n",
              " 'mesmerize': 27636,\n",
              " 'quinnell': 52058,\n",
              " 'yahoo': 10310,\n",
              " 'meteorologist': 52060,\n",
              " 'beswick': 42580,\n",
              " 'boorman': 15496,\n",
              " 'voicework': 40850,\n",
              " \"ster'\": 52061,\n",
              " 'blustering': 22925,\n",
              " 'hj': 52062,\n",
              " 'intake': 27637,\n",
              " 'morally': 5624,\n",
              " 'jumbling': 40852,\n",
              " 'bowersock': 52063,\n",
              " \"'porky's'\": 52064,\n",
              " 'gershon': 16824,\n",
              " 'ludicrosity': 40853,\n",
              " 'coprophilia': 52065,\n",
              " 'expressively': 40854,\n",
              " \"india's\": 19503,\n",
              " \"post's\": 34713,\n",
              " 'wana': 52066,\n",
              " 'wang': 5286,\n",
              " 'wand': 30574,\n",
              " 'wane': 25248,\n",
              " 'edgeways': 52324,\n",
              " 'titanium': 34714,\n",
              " 'pinta': 40855,\n",
              " 'want': 181,\n",
              " 'pinto': 30575,\n",
              " 'whoopdedoodles': 52068,\n",
              " 'tchaikovsky': 21911,\n",
              " 'travel': 2106,\n",
              " \"'victory'\": 52069,\n",
              " 'copious': 11931,\n",
              " 'gouge': 22436,\n",
              " \"chapters'\": 52070,\n",
              " 'barbra': 6705,\n",
              " 'uselessness': 30576,\n",
              " \"wan'\": 52071,\n",
              " 'assimilated': 27638,\n",
              " 'petiot': 16119,\n",
              " 'most\\x85and': 52072,\n",
              " 'dinosaurs': 3933,\n",
              " 'wrong': 355,\n",
              " 'seda': 52073,\n",
              " 'stollen': 52074,\n",
              " 'sentencing': 34715,\n",
              " 'ouroboros': 40856,\n",
              " 'assimilates': 40857,\n",
              " 'colorfully': 40858,\n",
              " 'glenne': 27639,\n",
              " 'dongen': 52075,\n",
              " 'subplots': 4763,\n",
              " 'kiloton': 52076,\n",
              " 'chandon': 23384,\n",
              " \"effect'\": 34716,\n",
              " 'snugly': 27640,\n",
              " 'kuei': 40859,\n",
              " 'welcomed': 9095,\n",
              " 'dishonor': 30074,\n",
              " 'concurrence': 52078,\n",
              " 'stoicism': 23385,\n",
              " \"guys'\": 14899,\n",
              " \"beroemd'\": 52080,\n",
              " 'butcher': 6706,\n",
              " \"melfi's\": 40860,\n",
              " 'aargh': 30626,\n",
              " 'playhouse': 20602,\n",
              " 'wickedly': 11311,\n",
              " 'fit': 1183,\n",
              " 'labratory': 52081,\n",
              " 'lifeline': 40862,\n",
              " 'screaming': 1930,\n",
              " 'fix': 4290,\n",
              " 'cineliterate': 52082,\n",
              " 'fic': 52083,\n",
              " 'fia': 52084,\n",
              " 'fig': 34717,\n",
              " 'fmvs': 52085,\n",
              " 'fie': 52086,\n",
              " 'reentered': 52087,\n",
              " 'fin': 30577,\n",
              " 'doctresses': 52088,\n",
              " 'fil': 52089,\n",
              " 'zucker': 12609,\n",
              " 'ached': 31934,\n",
              " 'counsil': 52091,\n",
              " 'paterfamilias': 52092,\n",
              " 'songwriter': 13888,\n",
              " 'shivam': 34718,\n",
              " 'hurting': 9657,\n",
              " 'effects': 302,\n",
              " 'slauther': 52093,\n",
              " \"'flame'\": 52094,\n",
              " 'sommerset': 52095,\n",
              " 'interwhined': 52096,\n",
              " 'whacking': 27641,\n",
              " 'bartok': 52097,\n",
              " 'barton': 8778,\n",
              " 'frewer': 21912,\n",
              " \"fi'\": 52098,\n",
              " 'ingrid': 6195,\n",
              " 'stribor': 30578,\n",
              " 'approporiately': 52099,\n",
              " 'wobblyhand': 52100,\n",
              " 'tantalisingly': 52101,\n",
              " 'ankylosaurus': 52102,\n",
              " 'parasites': 17637,\n",
              " 'childen': 52103,\n",
              " \"jenkins'\": 52104,\n",
              " 'metafiction': 52105,\n",
              " 'golem': 17638,\n",
              " 'indiscretion': 40863,\n",
              " \"reeves'\": 23386,\n",
              " \"inamorata's\": 57784,\n",
              " 'brittannica': 52107,\n",
              " 'adapt': 7919,\n",
              " \"russo's\": 30579,\n",
              " 'guitarists': 48249,\n",
              " 'abbott': 10556,\n",
              " 'abbots': 40864,\n",
              " 'lanisha': 17652,\n",
              " 'magickal': 40866,\n",
              " 'mattter': 52108,\n",
              " \"'willy\": 52109,\n",
              " 'pumpkins': 34719,\n",
              " 'stuntpeople': 52110,\n",
              " 'estimate': 30580,\n",
              " 'ugghhh': 40867,\n",
              " 'gameplay': 11312,\n",
              " \"wern't\": 52111,\n",
              " \"n'sync\": 40868,\n",
              " 'sickeningly': 16120,\n",
              " 'chiara': 40869,\n",
              " 'disturbed': 4014,\n",
              " 'portmanteau': 40870,\n",
              " 'ineffectively': 52112,\n",
              " \"duchonvey's\": 82146,\n",
              " \"nasty'\": 37522,\n",
              " 'purpose': 1288,\n",
              " 'lazers': 52115,\n",
              " 'lightened': 28108,\n",
              " 'kaliganj': 52116,\n",
              " 'popularism': 52117,\n",
              " \"damme's\": 18514,\n",
              " 'stylistics': 30581,\n",
              " 'mindgaming': 52118,\n",
              " 'spoilerish': 46452,\n",
              " \"'corny'\": 52120,\n",
              " 'boerner': 34721,\n",
              " 'olds': 6795,\n",
              " 'bakelite': 52121,\n",
              " 'renovated': 27642,\n",
              " 'forrester': 27643,\n",
              " \"lumiere's\": 52122,\n",
              " 'gaskets': 52027,\n",
              " 'needed': 887,\n",
              " 'smight': 34722,\n",
              " 'master': 1300,\n",
              " \"edie's\": 25908,\n",
              " 'seeber': 40871,\n",
              " 'hiya': 52123,\n",
              " 'fuzziness': 52124,\n",
              " 'genesis': 14900,\n",
              " 'rewards': 12610,\n",
              " 'enthrall': 30582,\n",
              " \"'about\": 40872,\n",
              " \"recollection's\": 52125,\n",
              " 'mutilated': 11042,\n",
              " 'fatherlands': 52126,\n",
              " \"fischer's\": 52127,\n",
              " 'positively': 5402,\n",
              " '270': 34708,\n",
              " 'ahmed': 34723,\n",
              " 'zatoichi': 9839,\n",
              " 'bannister': 13889,\n",
              " 'anniversaries': 52130,\n",
              " \"helm's\": 30583,\n",
              " \"'work'\": 52131,\n",
              " 'exclaimed': 34724,\n",
              " \"'unfunny'\": 52132,\n",
              " '274': 52032,\n",
              " 'feeling': 547,\n",
              " \"wanda's\": 52134,\n",
              " 'dolan': 33269,\n",
              " '278': 52136,\n",
              " 'peacoat': 52137,\n",
              " 'brawny': 40873,\n",
              " 'mishra': 40874,\n",
              " 'worlders': 40875,\n",
              " 'protags': 52138,\n",
              " 'skullcap': 52139,\n",
              " 'dastagir': 57599,\n",
              " 'affairs': 5625,\n",
              " 'wholesome': 7802,\n",
              " 'hymen': 52140,\n",
              " 'paramedics': 25249,\n",
              " 'unpersons': 52141,\n",
              " 'heavyarms': 52142,\n",
              " 'affaire': 52143,\n",
              " 'coulisses': 52144,\n",
              " 'hymer': 40876,\n",
              " 'kremlin': 52145,\n",
              " 'shipments': 30584,\n",
              " 'pixilated': 52146,\n",
              " \"'00s\": 30585,\n",
              " 'diminishing': 18515,\n",
              " 'cinematic': 1360,\n",
              " 'resonates': 14901,\n",
              " 'simplify': 40877,\n",
              " \"nature'\": 40878,\n",
              " 'temptresses': 40879,\n",
              " 'reverence': 16825,\n",
              " 'resonated': 19505,\n",
              " 'dailey': 34725,\n",
              " '2\\x85': 52147,\n",
              " 'treize': 27644,\n",
              " 'majo': 52148,\n",
              " 'kiya': 21913,\n",
              " 'woolnough': 52149,\n",
              " 'thanatos': 39800,\n",
              " 'sandoval': 35734,\n",
              " 'dorama': 40882,\n",
              " \"o'shaughnessy\": 52150,\n",
              " 'tech': 4991,\n",
              " 'fugitives': 32021,\n",
              " 'teck': 30586,\n",
              " \"'e'\": 76128,\n",
              " 'doesnt': 40884,\n",
              " 'purged': 52152,\n",
              " 'saying': 660,\n",
              " \"martians'\": 41098,\n",
              " 'norliss': 23421,\n",
              " 'dickey': 27645,\n",
              " 'dicker': 52155,\n",
              " \"'sependipity\": 52156,\n",
              " 'padded': 8425,\n",
              " 'ordell': 57795,\n",
              " \"sturges'\": 40885,\n",
              " 'independentcritics': 52157,\n",
              " 'tempted': 5748,\n",
              " \"atkinson's\": 34727,\n",
              " 'hounded': 25250,\n",
              " 'apace': 52158,\n",
              " 'clicked': 15497,\n",
              " \"'humor'\": 30587,\n",
              " \"martino's\": 17180,\n",
              " \"'supporting\": 52159,\n",
              " 'warmongering': 52035,\n",
              " \"zemeckis's\": 34728,\n",
              " 'lube': 21914,\n",
              " 'shocky': 52160,\n",
              " 'plate': 7479,\n",
              " 'plata': 40886,\n",
              " 'sturgess': 40887,\n",
              " \"nerds'\": 40888,\n",
              " 'plato': 20603,\n",
              " 'plath': 34729,\n",
              " 'platt': 40889,\n",
              " 'mcnab': 52162,\n",
              " 'clumsiness': 27646,\n",
              " 'altogether': 3902,\n",
              " 'massacring': 42587,\n",
              " 'bicenntinial': 52163,\n",
              " 'skaal': 40890,\n",
              " 'droning': 14363,\n",
              " 'lds': 8779,\n",
              " 'jaguar': 21915,\n",
              " \"cale's\": 34730,\n",
              " 'nicely': 1780,\n",
              " 'mummy': 4591,\n",
              " \"lot's\": 18516,\n",
              " 'patch': 10089,\n",
              " 'kerkhof': 50205,\n",
              " \"leader's\": 52164,\n",
              " \"'movie\": 27647,\n",
              " 'uncomfirmed': 52165,\n",
              " 'heirloom': 40891,\n",
              " 'wrangle': 47363,\n",
              " 'emotion\\x85': 52166,\n",
              " \"'stargate'\": 52167,\n",
              " 'pinoy': 40892,\n",
              " 'conchatta': 40893,\n",
              " 'broeke': 41131,\n",
              " 'advisedly': 40894,\n",
              " \"barker's\": 17639,\n",
              " 'descours': 52169,\n",
              " 'lots': 775,\n",
              " 'lotr': 9262,\n",
              " 'irs': 9882,\n",
              " 'lott': 52170,\n",
              " 'xvi': 40895,\n",
              " 'irk': 34731,\n",
              " 'irl': 52171,\n",
              " 'ira': 6890,\n",
              " 'belzer': 21916,\n",
              " 'irc': 52172,\n",
              " 'ire': 27648,\n",
              " 'requisites': 40896,\n",
              " 'discipline': 7696,\n",
              " 'lyoko': 52964,\n",
              " 'extend': 11313,\n",
              " 'nature': 876,\n",
              " \"'dickie'\": 52173,\n",
              " 'optimist': 40897,\n",
              " 'lapping': 30589,\n",
              " 'superficial': 3903,\n",
              " 'vestment': 52174,\n",
              " 'extent': 2826,\n",
              " 'tendons': 52175,\n",
              " \"heller's\": 52176,\n",
              " 'quagmires': 52177,\n",
              " 'miyako': 52178,\n",
              " 'moocow': 20604,\n",
              " \"coles'\": 52179,\n",
              " 'lookit': 40898,\n",
              " 'ravenously': 52180,\n",
              " 'levitating': 40899,\n",
              " 'perfunctorily': 52181,\n",
              " 'lookin': 30590,\n",
              " \"lot'\": 40901,\n",
              " 'lookie': 52182,\n",
              " 'fearlessly': 34873,\n",
              " 'libyan': 52184,\n",
              " 'fondles': 40902,\n",
              " 'gopher': 35717,\n",
              " 'wearying': 40904,\n",
              " \"nz's\": 52185,\n",
              " 'minuses': 27649,\n",
              " 'puposelessly': 52186,\n",
              " 'shandling': 52187,\n",
              " 'decapitates': 31271,\n",
              " 'humming': 11932,\n",
              " \"'nother\": 40905,\n",
              " 'smackdown': 21917,\n",
              " 'underdone': 30591,\n",
              " 'frf': 40906,\n",
              " 'triviality': 52188,\n",
              " 'fro': 25251,\n",
              " 'bothers': 8780,\n",
              " \"'kensington\": 52189,\n",
              " 'much': 76,\n",
              " 'muco': 34733,\n",
              " 'wiseguy': 22618,\n",
              " \"richie's\": 27651,\n",
              " 'tonino': 40907,\n",
              " 'unleavened': 52190,\n",
              " 'fry': 11590,\n",
              " \"'tv'\": 40908,\n",
              " 'toning': 40909,\n",
              " 'obese': 14364,\n",
              " 'sensationalized': 30592,\n",
              " 'spiv': 40910,\n",
              " 'spit': 6262,\n",
              " 'arkin': 7367,\n",
              " 'charleton': 21918,\n",
              " 'jeon': 16826,\n",
              " 'boardroom': 21919,\n",
              " 'doubts': 4992,\n",
              " 'spin': 3087,\n",
              " 'hepo': 53086,\n",
              " 'wildcat': 27652,\n",
              " 'venoms': 10587,\n",
              " 'misconstrues': 52194,\n",
              " 'mesmerising': 18517,\n",
              " 'misconstrued': 40911,\n",
              " 'rescinds': 52195,\n",
              " 'prostrate': 52196,\n",
              " 'majid': 40912,\n",
              " 'climbed': 16482,\n",
              " 'canoeing': 34734,\n",
              " 'majin': 52198,\n",
              " 'animie': 57807,\n",
              " 'sylke': 40913,\n",
              " 'conditioned': 14902,\n",
              " 'waddell': 40914,\n",
              " '3\\x85': 52199,\n",
              " 'hyperdrive': 41191,\n",
              " 'conditioner': 34735,\n",
              " 'bricklayer': 53156,\n",
              " 'hong': 2579,\n",
              " 'memoriam': 52201,\n",
              " 'inventively': 30595,\n",
              " \"levant's\": 25252,\n",
              " 'portobello': 20641,\n",
              " 'remand': 52203,\n",
              " 'mummified': 19507,\n",
              " 'honk': 27653,\n",
              " 'spews': 19508,\n",
              " 'visitations': 40915,\n",
              " 'mummifies': 52204,\n",
              " 'cavanaugh': 25253,\n",
              " 'zeon': 23388,\n",
              " \"jungle's\": 40916,\n",
              " 'viertel': 34736,\n",
              " 'frenchmen': 27654,\n",
              " 'torpedoes': 52205,\n",
              " 'schlessinger': 52206,\n",
              " 'torpedoed': 34737,\n",
              " 'blister': 69879,\n",
              " 'cinefest': 52207,\n",
              " 'furlough': 34738,\n",
              " 'mainsequence': 52208,\n",
              " 'mentors': 40917,\n",
              " 'academic': 9097,\n",
              " 'stillness': 20605,\n",
              " 'academia': 40918,\n",
              " 'lonelier': 52209,\n",
              " 'nibby': 52210,\n",
              " \"losers'\": 52211,\n",
              " 'cineastes': 40919,\n",
              " 'corporate': 4452,\n",
              " 'massaging': 40920,\n",
              " 'bellow': 30596,\n",
              " 'absurdities': 19509,\n",
              " 'expetations': 53244,\n",
              " 'nyfiken': 40921,\n",
              " 'mehras': 75641,\n",
              " 'lasse': 52212,\n",
              " 'visability': 52213,\n",
              " 'militarily': 33949,\n",
              " \"elder'\": 52214,\n",
              " 'gainsbourg': 19026,\n",
              " 'hah': 20606,\n",
              " 'hai': 13423,\n",
              " 'haj': 34739,\n",
              " 'hak': 25254,\n",
              " 'hal': 4314,\n",
              " 'ham': 4895,\n",
              " 'duffer': 53262,\n",
              " 'haa': 52216,\n",
              " 'had': 69,\n",
              " 'advancement': 11933,\n",
              " 'hag': 16828,\n",
              " \"hand'\": 25255,\n",
              " 'hay': 13424,\n",
              " 'mcnamara': 20607,\n",
              " \"mozart's\": 52217,\n",
              " 'duffel': 30734,\n",
              " 'haq': 30597,\n",
              " 'har': 13890,\n",
              " 'has': 47,\n",
              " 'hat': 2404,\n",
              " 'hav': 40922,\n",
              " 'haw': 30598,\n",
              " 'figtings': 52218,\n",
              " 'elders': 15498,\n",
              " 'underpanted': 52219,\n",
              " 'pninson': 52220,\n",
              " 'unequivocally': 27655,\n",
              " \"barbara's\": 23676,\n",
              " \"bello'\": 52222,\n",
              " 'indicative': 13000,\n",
              " 'yawnfest': 40923,\n",
              " 'hexploitation': 52223,\n",
              " \"loder's\": 52224,\n",
              " 'sleuthing': 27656,\n",
              " \"justin's\": 32625,\n",
              " \"'ball\": 52225,\n",
              " \"'summer\": 52226,\n",
              " \"'demons'\": 34938,\n",
              " \"mormon's\": 52228,\n",
              " \"laughton's\": 34740,\n",
              " 'debell': 52229,\n",
              " 'shipyard': 39727,\n",
              " 'unabashedly': 30600,\n",
              " 'disks': 40404,\n",
              " 'crowd': 2293,\n",
              " 'crowe': 10090,\n",
              " \"vancouver's\": 56437,\n",
              " 'mosques': 34741,\n",
              " 'crown': 6630,\n",
              " 'culpas': 52230,\n",
              " 'crows': 27657,\n",
              " 'surrell': 53347,\n",
              " 'flowless': 52232,\n",
              " 'sheirk': 52233,\n",
              " \"'three\": 40926,\n",
              " \"peterson'\": 52234,\n",
              " 'ooverall': 52235,\n",
              " 'perchance': 40927,\n",
              " 'bottom': 1324,\n",
              " 'chabert': 53366,\n",
              " 'sneha': 52236,\n",
              " 'inhuman': 13891,\n",
              " 'ichii': 52237,\n",
              " 'ursla': 52238,\n",
              " 'completly': 30601,\n",
              " 'moviedom': 40928,\n",
              " 'raddick': 52239,\n",
              " 'brundage': 51998,\n",
              " 'brigades': 40929,\n",
              " 'starring': 1184,\n",
              " \"'goal'\": 52240,\n",
              " 'caskets': 52241,\n",
              " 'willcock': 52242,\n",
              " \"threesome's\": 52243,\n",
              " \"mosque'\": 52244,\n",
              " \"cover's\": 52245,\n",
              " 'spaceships': 17640,\n",
              " 'anomalous': 40930,\n",
              " 'ptsd': 27658,\n",
              " 'shirdan': 52246,\n",
              " 'obscenity': 21965,\n",
              " 'lemmings': 30602,\n",
              " 'duccio': 30603,\n",
              " \"levene's\": 52247,\n",
              " \"'gorby'\": 52248,\n",
              " \"teenager's\": 25258,\n",
              " 'marshall': 5343,\n",
              " 'honeymoon': 9098,\n",
              " 'shoots': 3234,\n",
              " 'despised': 12261,\n",
              " 'okabasho': 52249,\n",
              " 'fabric': 8292,\n",
              " 'cannavale': 18518,\n",
              " 'raped': 3540,\n",
              " \"tutt's\": 52250,\n",
              " 'grasping': 17641,\n",
              " 'despises': 18519,\n",
              " \"thief's\": 40931,\n",
              " 'rapes': 8929,\n",
              " 'raper': 52251,\n",
              " \"eyre'\": 27659,\n",
              " 'walchek': 52252,\n",
              " \"elmo's\": 23389,\n",
              " 'perfumes': 40932,\n",
              " 'spurting': 21921,\n",
              " \"exposition'\\x85\": 52253,\n",
              " 'denoting': 52254,\n",
              " 'thesaurus': 34743,\n",
              " \"shoot'\": 40933,\n",
              " 'bonejack': 49762,\n",
              " 'simpsonian': 52256,\n",
              " 'hebetude': 30604,\n",
              " \"hallow's\": 34744,\n",
              " 'desperation\\x85': 52257,\n",
              " 'incinerator': 34745,\n",
              " 'congratulations': 10311,\n",
              " 'humbled': 52258,\n",
              " \"else's\": 5927,\n",
              " 'trelkovski': 40848,\n",
              " \"rape'\": 52259,\n",
              " \"'chapters'\": 59389,\n",
              " '1600s': 52260,\n",
              " 'martian': 7256,\n",
              " 'nicest': 25259,\n",
              " 'eyred': 52262,\n",
              " 'passenger': 9460,\n",
              " 'disgrace': 6044,\n",
              " 'moderne': 52263,\n",
              " 'barrymore': 5123,\n",
              " 'yankovich': 52264,\n",
              " 'moderns': 40934,\n",
              " 'studliest': 52265,\n",
              " 'bedsheet': 52266,\n",
              " 'decapitation': 14903,\n",
              " 'slurring': 52267,\n",
              " \"'nunsploitation'\": 52268,\n",
              " \"'character'\": 34746,\n",
              " 'cambodia': 9883,\n",
              " 'rebelious': 52269,\n",
              " 'pasadena': 27660,\n",
              " 'crowne': 40935,\n",
              " \"'bedchamber\": 52270,\n",
              " 'conjectural': 52271,\n",
              " 'appologize': 52272,\n",
              " 'halfassing': 52273,\n",
              " 'paycheque': 57819,\n",
              " 'palms': 20609,\n",
              " \"'islands\": 52274,\n",
              " 'hawked': 40936,\n",
              " 'palme': 21922,\n",
              " 'conservatively': 40937,\n",
              " 'larp': 64010,\n",
              " 'palma': 5561,\n",
              " 'smelling': 21923,\n",
              " 'aragorn': 13001,\n",
              " 'hawker': 52275,\n",
              " 'hawkes': 52276,\n",
              " 'explosions': 3978,\n",
              " 'loren': 8062,\n",
              " \"pyle's\": 52277,\n",
              " 'shootout': 6707,\n",
              " \"mike's\": 18520,\n",
              " \"driscoll's\": 52278,\n",
              " 'cogsworth': 40938,\n",
              " \"britian's\": 52279,\n",
              " 'childs': 34747,\n",
              " \"portrait's\": 52280,\n",
              " 'chain': 3629,\n",
              " 'whoever': 2500,\n",
              " 'puttered': 52281,\n",
              " 'childe': 52282,\n",
              " 'maywether': 52283,\n",
              " 'chair': 3039,\n",
              " \"rance's\": 52284,\n",
              " 'machu': 34748,\n",
              " 'ballet': 4520,\n",
              " 'grapples': 34749,\n",
              " 'summerize': 76155,\n",
              " 'freelance': 30606,\n",
              " \"andrea's\": 52286,\n",
              " '\\x91very': 52287,\n",
              " 'coolidge': 45882,\n",
              " 'mache': 18521,\n",
              " 'balled': 52288,\n",
              " 'grappled': 40940,\n",
              " 'macha': 18522,\n",
              " 'underlining': 21924,\n",
              " 'macho': 5626,\n",
              " 'oversight': 19510,\n",
              " 'machi': 25260,\n",
              " 'verbally': 11314,\n",
              " 'tenacious': 21925,\n",
              " 'windshields': 40941,\n",
              " 'paychecks': 18560,\n",
              " 'jerk': 3399,\n",
              " \"good'\": 11934,\n",
              " 'prancer': 34751,\n",
              " 'prances': 21926,\n",
              " 'olympus': 52289,\n",
              " 'lark': 21927,\n",
              " 'embark': 10788,\n",
              " 'gloomy': 7368,\n",
              " 'jehaan': 52290,\n",
              " 'turaqui': 52291,\n",
              " \"child'\": 20610,\n",
              " 'locked': 2897,\n",
              " 'pranced': 52292,\n",
              " 'exact': 2591,\n",
              " 'unattuned': 52293,\n",
              " 'minute': 786,\n",
              " 'skewed': 16121,\n",
              " 'hodgins': 40943,\n",
              " 'skewer': 34752,\n",
              " 'think\\x85': 52294,\n",
              " 'rosenstein': 38768,\n",
              " 'helmit': 52295,\n",
              " 'wrestlemanias': 34753,\n",
              " 'hindered': 16829,\n",
              " \"martha's\": 30607,\n",
              " 'cheree': 52296,\n",
              " \"pluckin'\": 52297,\n",
              " 'ogles': 40944,\n",
              " 'heavyweight': 11935,\n",
              " 'aada': 82193,\n",
              " 'chopping': 11315,\n",
              " 'strongboy': 61537,\n",
              " 'hegemonic': 41345,\n",
              " 'adorns': 40945,\n",
              " 'xxth': 41349,\n",
              " 'nobuhiro': 34754,\n",
              " 'capites': 52301,\n",
              " 'kavogianni': 52302,\n",
              " 'antwerp': 13425,\n",
              " 'celebrated': 6541,\n",
              " 'roarke': 52303,\n",
              " 'baggins': 40946,\n",
              " 'cheeseburgers': 31273,\n",
              " 'matras': 52304,\n",
              " \"nineties'\": 52305,\n",
              " \"'craig'\": 52306,\n",
              " 'celebrates': 13002,\n",
              " 'unintentionally': 3386,\n",
              " 'drafted': 14365,\n",
              " 'climby': 52307,\n",
              " '303': 52308,\n",
              " 'oldies': 18523,\n",
              " 'climbs': 9099,\n",
              " 'honour': 9658,\n",
              " 'plucking': 34755,\n",
              " '305': 30077,\n",
              " 'address': 5517,\n",
              " 'menjou': 40947,\n",
              " \"'freak'\": 42595,\n",
              " 'dwindling': 19511,\n",
              " 'benson': 9461,\n",
              " 'whites': 52310,\n",
              " 'shamelessness': 40948,\n",
              " 'impacted': 21928,\n",
              " 'upatz': 52311,\n",
              " 'cusack': 3843,\n",
              " \"flavia's\": 37570,\n",
              " 'effette': 52312,\n",
              " 'influx': 34756,\n",
              " 'boooooooo': 52313,\n",
              " 'dimitrova': 52314,\n",
              " 'houseman': 13426,\n",
              " 'bigas': 25262,\n",
              " 'boylen': 52315,\n",
              " 'phillipenes': 52316,\n",
              " 'fakery': 40949,\n",
              " \"grandpa's\": 27661,\n",
              " 'darnell': 27662,\n",
              " 'undergone': 19512,\n",
              " 'handbags': 52318,\n",
              " 'perished': 21929,\n",
              " 'pooped': 37781,\n",
              " 'vigour': 27663,\n",
              " 'opposed': 3630,\n",
              " 'etude': 52319,\n",
              " \"caine's\": 11802,\n",
              " 'doozers': 52320,\n",
              " 'photojournals': 34757,\n",
              " 'perishes': 52321,\n",
              " 'constrains': 34758,\n",
              " 'migenes': 40951,\n",
              " 'consoled': 30608,\n",
              " 'alastair': 16830,\n",
              " 'wvs': 52322,\n",
              " 'ooooooh': 52323,\n",
              " 'approving': 34759,\n",
              " 'consoles': 40952,\n",
              " 'disparagement': 52067,\n",
              " 'futureistic': 52325,\n",
              " 'rebounding': 52326,\n",
              " \"'date\": 52327,\n",
              " 'gregoire': 52328,\n",
              " 'rutherford': 21930,\n",
              " 'americanised': 34760,\n",
              " 'novikov': 82199,\n",
              " 'following': 1045,\n",
              " 'munroe': 34761,\n",
              " \"morita'\": 52329,\n",
              " 'christenssen': 52330,\n",
              " 'oatmeal': 23109,\n",
              " 'fossey': 25263,\n",
              " 'livered': 40953,\n",
              " 'listens': 13003,\n",
              " \"'marci\": 76167,\n",
              " \"otis's\": 52333,\n",
              " 'thanking': 23390,\n",
              " 'maude': 16022,\n",
              " 'extensions': 34762,\n",
              " 'ameteurish': 52335,\n",
              " \"commender's\": 52336,\n",
              " 'agricultural': 27664,\n",
              " 'convincingly': 4521,\n",
              " 'fueled': 17642,\n",
              " 'mahattan': 54017,\n",
              " \"paris's\": 40955,\n",
              " 'vulkan': 52339,\n",
              " 'stapes': 52340,\n",
              " 'odysessy': 52341,\n",
              " 'harmon': 12262,\n",
              " 'surfing': 4255,\n",
              " 'halloran': 23497,\n",
              " 'unbelieveably': 49583,\n",
              " \"'offed'\": 52342,\n",
              " 'quadrant': 30610,\n",
              " 'inhabiting': 19513,\n",
              " 'nebbish': 34763,\n",
              " 'forebears': 40956,\n",
              " 'skirmish': 34764,\n",
              " 'ocassionally': 52343,\n",
              " \"'resist\": 52344,\n",
              " 'impactful': 21931,\n",
              " 'spicier': 52345,\n",
              " 'touristy': 40957,\n",
              " \"'football'\": 52346,\n",
              " 'webpage': 40958,\n",
              " 'exurbia': 52348,\n",
              " 'jucier': 52349,\n",
              " 'professors': 14904,\n",
              " 'structuring': 34765,\n",
              " 'jig': 30611,\n",
              " 'overlord': 40959,\n",
              " 'disconnect': 25264,\n",
              " 'sniffle': 82204,\n",
              " 'slimeball': 40960,\n",
              " 'jia': 40961,\n",
              " 'milked': 16831,\n",
              " 'banjoes': 40962,\n",
              " 'jim': 1240,\n",
              " 'workforces': 52351,\n",
              " 'jip': 52352,\n",
              " 'rotweiller': 52353,\n",
              " 'mundaneness': 34766,\n",
              " \"'ninja'\": 52354,\n",
              " \"dead'\": 11043,\n",
              " \"cipriani's\": 40963,\n",
              " 'modestly': 20611,\n",
              " \"professor'\": 52355,\n",
              " 'shacked': 40964,\n",
              " 'bashful': 34767,\n",
              " 'sorter': 23391,\n",
              " 'overpowering': 16123,\n",
              " 'workmanlike': 18524,\n",
              " 'henpecked': 27665,\n",
              " 'sorted': 18525,\n",
              " \"jb's\": 52357,\n",
              " \"'always\": 52358,\n",
              " \"'baptists\": 34768,\n",
              " 'dreamcatchers': 52359,\n",
              " \"'silence'\": 52360,\n",
              " 'hickory': 21932,\n",
              " 'fun\\x97yet': 52361,\n",
              " 'breakumentary': 52362,\n",
              " 'didn': 15499,\n",
              " 'didi': 52363,\n",
              " 'pealing': 52364,\n",
              " 'dispite': 40965,\n",
              " \"italy's\": 25265,\n",
              " 'instability': 21933,\n",
              " 'quarter': 6542,\n",
              " 'quartet': 12611,\n",
              " 'padm': 52365,\n",
              " \"'bleedmedry\": 52366,\n",
              " 'pahalniuk': 52367,\n",
              " 'honduras': 52368,\n",
              " 'bursting': 10789,\n",
              " \"pablo's\": 41468,\n",
              " 'irremediably': 52370,\n",
              " 'presages': 40966,\n",
              " 'bowlegged': 57835,\n",
              " 'dalip': 65186,\n",
              " 'entering': 6263,\n",
              " 'newsradio': 76175,\n",
              " 'presaged': 54153,\n",
              " \"giallo's\": 27666,\n",
              " 'bouyant': 40967,\n",
              " 'amerterish': 52371,\n",
              " 'rajni': 18526,\n",
              " 'leeves': 30613,\n",
              " 'macauley': 34770,\n",
              " 'seriously': 615,\n",
              " 'sugercoma': 52372,\n",
              " 'grimstead': 52373,\n",
              " \"'fairy'\": 52374,\n",
              " 'zenda': 30614,\n",
              " \"'twins'\": 52375,\n",
              " 'realisation': 17643,\n",
              " 'highsmith': 27667,\n",
              " 'raunchy': 7820,\n",
              " 'incentives': 40968,\n",
              " 'flatson': 52377,\n",
              " 'snooker': 35100,\n",
              " 'crazies': 16832,\n",
              " 'crazier': 14905,\n",
              " 'grandma': 7097,\n",
              " 'napunsaktha': 52378,\n",
              " 'workmanship': 30615,\n",
              " 'reisner': 52379,\n",
              " \"sanford's\": 61309,\n",
              " '\\x91doa': 52380,\n",
              " 'modest': 6111,\n",
              " \"everything's\": 19156,\n",
              " 'hamer': 40969,\n",
              " \"couldn't'\": 52382,\n",
              " 'quibble': 13004,\n",
              " 'socking': 52383,\n",
              " 'tingler': 21934,\n",
              " 'gutman': 52384,\n",
              " 'lachlan': 40970,\n",
              " 'tableaus': 52385,\n",
              " 'headbanger': 52386,\n",
              " 'spoken': 2850,\n",
              " 'cerebrally': 34771,\n",
              " \"'road\": 23493,\n",
              " 'tableaux': 21935,\n",
              " \"proust's\": 40971,\n",
              " 'periodical': 40972,\n",
              " \"shoveller's\": 52388,\n",
              " 'tamara': 25266,\n",
              " 'affords': 17644,\n",
              " 'concert': 3252,\n",
              " \"yara's\": 87958,\n",
              " 'someome': 52389,\n",
              " 'lingering': 8427,\n",
              " \"abraham's\": 41514,\n",
              " 'beesley': 34772,\n",
              " 'cherbourg': 34773,\n",
              " 'kagan': 28627,\n",
              " 'snatch': 9100,\n",
              " \"miyazaki's\": 9263,\n",
              " 'absorbs': 25267,\n",
              " \"koltai's\": 40973,\n",
              " 'tingled': 64030,\n",
              " 'crossroads': 19514,\n",
              " 'rehab': 16124,\n",
              " 'falworth': 52392,\n",
              " 'sequals': 52393,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "7xMubRqJ_HNJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "11efb2ac-74fd-4615-9356-11ce861e4d3f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dist_v' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-046c1aced1b5>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# --- END CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dist_v' is not defined"
          ]
        }
      ],
      "source": [
        "if student:\n",
        "    # --- START CODE HERE (04)\n",
        "    emb_weights = model.layers[0].get_weights()\n",
        "    pos = word_to_id['great']\n",
        "    # --- END CODE HERE\n",
        "for i in np.argsort(dist_v)[0:20]: print(id_to_word[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK9e5Eo1Ks2a"
      },
      "source": [
        "# Second model\n",
        "\n",
        "In the second model, we will replace\n",
        "- the average over the sequence of the obtained embedding\n",
        "- by a RNN layer (more precisely an ```LSTM```) in a Many-To-One configuration with $n_a=128$\n",
        "\n",
        "We will code this model\n",
        "- First, using the Sequential API of keras (https://keras.io/models/sequential/)\n",
        "- Secondly, using the Functional API of keras (https://keras.io/getting-started/functional-api-guide/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwoXuOqqVDOy"
      },
      "outputs": [],
      "source": [
        "K.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dl-CSMKoViX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f0dc18-b212-4d99-99e9-72a2cbfb8d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_24 (Embedding)    (None, 100, 32)           160000    \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (None, 128)               82432     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 242561 (947.50 KB)\n",
            "Trainable params: 242561 (947.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# --- create the model\n",
        "\n",
        "if student:\n",
        "    # --- START CODE HERE (05)\n",
        "    # --- Using the Sequential API\n",
        "    ...\n",
        "    # --- END CODE HERE\n",
        "\n",
        "    # --- START CODE HERE (06)\n",
        "    # --- Using the Functional API\n",
        "    #model = ...\n",
        "    # --- END CODE HERE\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bp7PzX7oXtB",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8cb73b0-de50-4652-dcb6-8d128c35b9d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 28s 62ms/step - loss: 0.4480 - accuracy: 0.7796 - val_loss: 0.3460 - val_accuracy: 0.8487\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.3075 - accuracy: 0.8718 - val_loss: 0.3634 - val_accuracy: 0.8445\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.2736 - accuracy: 0.8888 - val_loss: 0.3553 - val_accuracy: 0.8470\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a9dcecfc970>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# --- compile and fit the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1LN_fjMWBHJ"
      },
      "source": [
        "## Results\n",
        "\n",
        "After only 3 epochs, you should obtain an accuracy around 84-85% for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlMEKRbzoavm"
      },
      "outputs": [],
      "source": [
        "# --- Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVK5sGgF_HNX"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "To evaluate the work, you should rate the code for\n",
        "- 1) Data Pre-Processing (01)\n",
        "- 2) First model using the Sequential API (02)\n",
        "- 3) First model using the Functional API (03)\n",
        "- 4) Find equivalence between words (04)\n",
        "- 5) Second model using the Sequential API (05)\n",
        "- 6) Second model using the Functional API (06)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}